{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Identifying At-Risk Students**\n",
    "Classifying students who may be at risk of underperforming, enabling targeted interventions to support them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FRANK\\anaconda3\\envs\\learn-env\\lib\\site-packages\\xgboost\\compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>ParentalEducation</th>\n",
       "      <th>StudyTimeWeekly</th>\n",
       "      <th>Absences</th>\n",
       "      <th>Tutoring</th>\n",
       "      <th>ParentalSupport</th>\n",
       "      <th>Extracurricular</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Music</th>\n",
       "      <th>Volunteering</th>\n",
       "      <th>GPA</th>\n",
       "      <th>GradeClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.833723</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.929196</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.408756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.042915</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.210570</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112602</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StudentID  Age  Gender  Ethnicity  ParentalEducation  StudyTimeWeekly  \\\n",
       "0       1001   17       1          0                  2        19.833723   \n",
       "1       1002   18       0          0                  1        15.408756   \n",
       "2       1003   15       0          2                  3         4.210570   \n",
       "\n",
       "   Absences  Tutoring  ParentalSupport  Extracurricular  Sports  Music  \\\n",
       "0         7         1                2                0       0      1   \n",
       "1         0         0                1                0       0      0   \n",
       "2        26         0                2                0       0      0   \n",
       "\n",
       "   Volunteering       GPA  GradeClass  \n",
       "0             0  2.929196         2.0  \n",
       "1             0  3.042915         1.0  \n",
       "2             0  0.112602         4.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"data/student_data.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['studentid', 'age', 'gender', 'ethnicity', 'parentaleducation',\n",
       "       'studytimeweekly', 'absences', 'tutoring', 'parentalsupport',\n",
       "       'extracurricular', 'sports', 'music', 'volunteering', 'gpa',\n",
       "       'gradeclass'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define 'At-Risk' Criteria\n",
    "Since we're not directly using the `gradeclass` column, we'll decide on what constitutes \"at-risk\" based on features like:\n",
    "\n",
    "- Absences: Define a threshold (e.g., >20 absences).\n",
    "- Parental Support: Low parental support as an indicator.\n",
    "- Study Time Weekly: Minimal weekly study time (e.g., <5 hours).\n",
    "- GPA: GPA below a certain threshold (e.g., <2.0).\n",
    "\n",
    "Then we'll create a binary target variable (at_risk) based on these criteria:\n",
    "\n",
    "- 1 for at-risk students.\n",
    "- 0 for students performing adequately.\n",
    "\n",
    "To simplify this process we'll be working with the most influential features in our previous models for predicting student gradeclass as they're already deemed suitable for determining student grades. We might as well apply the same to identify the students who may be at risk of underperforming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and inspect the summary statistics for the features of interest to help us refine thresholds for identifying at-risk students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['studentid', 'age', 'gender', 'ethnicity', 'parentaleducation',\n",
    "                'extracurricular', 'sports', 'music', 'volunteering', 'tutoring'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absences</th>\n",
       "      <th>parentalsupport</th>\n",
       "      <th>studytimeweekly</th>\n",
       "      <th>gpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2392.000000</td>\n",
       "      <td>2392.000000</td>\n",
       "      <td>2392.000000</td>\n",
       "      <td>2392.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.541388</td>\n",
       "      <td>2.122074</td>\n",
       "      <td>9.771992</td>\n",
       "      <td>1.906186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.467417</td>\n",
       "      <td>1.122813</td>\n",
       "      <td>5.652774</td>\n",
       "      <td>0.915156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.043079</td>\n",
       "      <td>1.174803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.705363</td>\n",
       "      <td>1.893393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.408410</td>\n",
       "      <td>2.622216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>19.978094</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          absences  parentalsupport  studytimeweekly          gpa\n",
       "count  2392.000000      2392.000000      2392.000000  2392.000000\n",
       "mean     14.541388         2.122074         9.771992     1.906186\n",
       "std       8.467417         1.122813         5.652774     0.915156\n",
       "min       0.000000         0.000000         0.001057     0.000000\n",
       "25%       7.000000         1.000000         5.043079     1.174803\n",
       "50%      15.000000         2.000000         9.705363     1.893393\n",
       "75%      22.000000         3.000000        14.408410     2.622216\n",
       "max      29.000000         4.000000        19.978094     4.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['absences', 'parentalsupport', 'studytimeweekly', 'gpa']\n",
    "df[features].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on what we have, we can implement the following threshold ideas:\n",
    "- Students with **absences > 22** (above the 75th percentile) could be considered at risk. This captures students with significantly higher absences compared to the majority.\n",
    "- Low parental support values (e.g. **<= 1**, which includes the bottom 25th percentile) could indicate at-risk students.\n",
    "- Students **studying < 5 hours weekly** (below the 25th percentile) could be flagged as at risk.\n",
    "- A **GPA < 1.17** (below the 25th percentile) could indicate at-risk students. This highlights those whose GPA is well below average.\n",
    "\n",
    "With this in mind, we will combine the thresholds to define the at-risk label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  -----------------------------------------------Approach 1---------------------------------------------------------\n",
    "# Since our goal for detection is **early detection** and **broad support** in the sense that we wish to capture students struggling in different aspects (e.g. attendance issues, \n",
    "# lack of study time, low gpa), we'll go with the **OR(|)** logic which is amore inclusive approach. This should help with early intervention, as even one risk factor can \n",
    "# negatively affect performance.\n",
    "\n",
    "# It's however worth noting that this logic might flag students who are actually doing well in some areas e.g. high GPA but many absenses and could subsequently lead to \n",
    "# false positives, increasing unnecessary interventions.\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "# # Define thresholds\n",
    "# absences_threshold = 22  \n",
    "# parentalsupport_threshold = 1  \n",
    "# studytime_threshold = 5  \n",
    "# gpa_threshold = 1.17\n",
    "\n",
    "# # Create 'at_risk' target\n",
    "# df['at_risk'] = np.where(\n",
    "#     (df['absences'] > absences_threshold) |\n",
    "#     (df['parentalsupport'] <= parentalsupport_threshold) |\n",
    "#     (df['studytimeweekly'] < studytime_threshold) |\n",
    "#     (df['gpa'] < gpa_threshold),\n",
    "#     1,  # At risk\n",
    "#     0   # Not at risk\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At-Risk Classification using Weighted Approach:\n",
      "0    1818\n",
      "1     574\n",
      "Name: at_risk_weighted, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define thresholds\n",
    "absences_threshold = 22  \n",
    "parentalsupport_threshold = 1  \n",
    "studytime_threshold = 5  \n",
    "gpa_threshold = 1.17\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'absences': 0.35,\n",
    "    'parentalsupport': 0.20,\n",
    "    'studytimeweekly': 0.20,\n",
    "    'gpa': 0.40\n",
    "}\n",
    "\n",
    "# Compute risk scores\n",
    "df['risk_score'] = (\n",
    "    (df['absences'] > absences_threshold) * weights['absences'] +\n",
    "    (df['parentalsupport'] <= parentalsupport_threshold) * weights['parentalsupport'] +\n",
    "    (df['studytimeweekly'] < studytime_threshold) * weights['studytimeweekly'] +\n",
    "    (df['gpa'] < gpa_threshold) * weights['gpa']\n",
    ")\n",
    "\n",
    "# Classify at-risk students based on threshold\n",
    "df['at_risk_weighted'] = np.where(df['risk_score'] >= 0.5, 1, 0)\n",
    "\n",
    "\n",
    "at_risk_weighted = df['at_risk_weighted'].value_counts()\n",
    "\n",
    "print(\"\\nAt-Risk Classification using Weighted Approach:\")\n",
    "print(at_risk_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count the number of at-risk and not-at-risk students\n",
    "at_risk_weighted_counts = df['at_risk_weighted'].value_counts()\n",
    "\n",
    "# Define labels and sizes for the pie chart\n",
    "labels = ['Not At-Risk', 'At-Risk']\n",
    "sizes = at_risk_weighted_counts.values\n",
    "\n",
    "# Define colors for better visualization\n",
    "colors = ['#1f77b4', '#ff7f0e']  # Blue and orange\n",
    "\n",
    "# Plot the pie chart\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(\n",
    "    sizes,\n",
    "    labels=labels,\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=90,\n",
    "    colors=colors,\n",
    "    wedgeprops={'edgecolor': 'white'}\n",
    ")\n",
    "plt.title('Proportion of At-Risk vs. Not At-Risk Students')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9061863027265407"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gpa'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Criteria 2: Weighted Approach ###\n",
    "\n",
    "# # Define risk factor weights (adjustable)\n",
    "# weights = {\n",
    "#     'absences': 1.5,  # High absences have strong impact\n",
    "#     'parentalsupport': 2.0,  # Lack of support is critical\n",
    "#     'studytimeweekly': 1.0,  # Low study time contributes\n",
    "#     'gpa': 2.5  # GPA is the strongest indicator\n",
    "# }\n",
    "\n",
    "# # Compute individual risk contributions (binary: 1 if criteria met, 0 otherwise)\n",
    "# df['risk_absences'] = np.where(df['absences'] > 22, 1, 0) * weights['absences']\n",
    "# df['risk_parentalsupport'] = np.where(df['parentalsupport'] <= 1, 1, 0) * weights['parentalsupport']\n",
    "# df['risk_studytime'] = np.where(df['studytimeweekly'] < 5, 1, 0) * weights['studytimeweekly']\n",
    "# df['risk_gpa'] = np.where(df['gpa'] < 1.17, 1, 0) * weights['gpa']\n",
    "\n",
    "# # Total risk score\n",
    "# df['total_risk_score'] = (\n",
    "#     df['risk_absences'] + df['risk_parentalsupport'] + \n",
    "#     df['risk_studytime'] + df['risk_gpa']\n",
    "# )\n",
    "\n",
    "# # Define at-risk threshold (e.g., total risk score >= 3.5)\n",
    "# df['at_risk1'] = np.where(df['total_risk_score'] >= 3.5, 1, 0)\n",
    "\n",
    "# # Drop temporary columns used for calculations if not needed\n",
    "# df.drop(columns=['risk_absences', 'risk_parentalsupport', 'risk_studytime', 'risk_gpa'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>studytimeweekly</th>\n",
       "      <th>absences</th>\n",
       "      <th>parentalsupport</th>\n",
       "      <th>gpa</th>\n",
       "      <th>gradeclass</th>\n",
       "      <th>risk_score</th>\n",
       "      <th>at_risk_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.833723</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2.929196</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.408756</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.042915</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.210570</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.112602</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.028829</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2.054218</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.672495</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1.288061</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.191219</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.084184</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.601680</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2.748237</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.424496</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1.360143</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.562008</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.896819</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.444466</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.573474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.851364</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.147172</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.598486</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1.559595</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.038712</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>1.520078</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12.101425</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>1.751581</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11.197811</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2.396788</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.728101</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1.341521</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.098656</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2.232175</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.528238</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1.384404</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16.254658</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0.469553</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.835206</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2.395784</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    studytimeweekly  absences  parentalsupport       gpa  gradeclass  \\\n",
       "0         19.833723         7                2  2.929196         2.0   \n",
       "1         15.408756         0                1  3.042915         1.0   \n",
       "2          4.210570        26                2  0.112602         4.0   \n",
       "3         10.028829        14                3  2.054218         3.0   \n",
       "4          4.672495        17                3  1.288061         4.0   \n",
       "5          8.191219         0                1  3.084184         1.0   \n",
       "6         15.601680        10                3  2.748237         2.0   \n",
       "7         15.424496        22                1  1.360143         4.0   \n",
       "8          4.562008         1                2  2.896819         2.0   \n",
       "9         18.444466         0                3  3.573474         0.0   \n",
       "10        11.851364        11                1  2.147172         3.0   \n",
       "11         7.598486        15                2  1.559595         4.0   \n",
       "12        10.038712        21                3  1.520078         4.0   \n",
       "13        12.101425        21                4  1.751581         4.0   \n",
       "14        11.197811         9                2  2.396788         3.0   \n",
       "15         9.728101        17                0  1.341521         4.0   \n",
       "16        10.098656        14                2  2.232175         3.0   \n",
       "17         3.528238        16                2  1.384404         4.0   \n",
       "18        16.254658        29                2  0.469553         4.0   \n",
       "19        10.835206         9                2  2.395784         3.0   \n",
       "\n",
       "    risk_score  at_risk_weighted  \n",
       "0         0.00                 0  \n",
       "1         0.20                 0  \n",
       "2         0.95                 1  \n",
       "3         0.00                 0  \n",
       "4         0.20                 0  \n",
       "5         0.20                 0  \n",
       "6         0.00                 0  \n",
       "7         0.20                 0  \n",
       "8         0.20                 0  \n",
       "9         0.00                 0  \n",
       "10        0.20                 0  \n",
       "11        0.00                 0  \n",
       "12        0.00                 0  \n",
       "13        0.00                 0  \n",
       "14        0.00                 0  \n",
       "15        0.20                 0  \n",
       "16        0.00                 0  \n",
       "17        0.20                 0  \n",
       "18        0.75                 1  \n",
       "19        0.00                 0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The **OR condition** is more lenient, marking a larger proportion (60%) of students as at-risk.\n",
    "\n",
    "    This is because a single risk factor is enough to classify a student as at-risk.\n",
    "\n",
    "    This approach might however overestimate the number of at-risk students, making it harder to target interventions effectively.\n",
    "\n",
    "- The **Weighted Approach** is more selective, classifying only 24% (574 students) as at-risk.\n",
    "\n",
    "    This ensures that students with multiple risk factors are identified, rather than those who have just one mild risk factor.\n",
    "\n",
    "    This approach might be more realistic because interventions can be prioritized for students facing multiple challenges which is what we choose to work with for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we defined the \"At-Risk\" label using the weighted approach, let's go ahead and build a machine learning model to predict whether a student is at risk based on their features.\n",
    "\n",
    "**1. Train-Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target variable (y)\n",
    "X = df.drop(columns=['at_risk_weighted', 'gradeclass', 'risk_score']) \n",
    "y = df['at_risk_weighted'] \n",
    "\n",
    "# Split into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Data Preprocessing**\n",
    "\n",
    "Our dataset contains categorical and numerical features that will need processing before feeding it into a model.\n",
    "\n",
    "- *Categorical Variables*: One-Hot Encoding for nominal features, and keep ordinal features as is.\n",
    "- *Numerical Variables*: Scaling (StandardScaler) for better model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define categorical and numerical features\n",
    "# binary_features = ['gender', 'tutoring', 'extracurricular', 'sports', 'music', 'volunteering']\n",
    "# ordinal_features = ['parentalsupport']\n",
    "# nominal_features = ['ethnicity', 'parentaleducation']\n",
    "# numerical_features = ['studytimeweekly', 'absences', 'gpa']\n",
    "\n",
    "# # Column transformer\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('onehot', OneHotEncoder(drop='first'), nominal_features),\n",
    "#         ('scale', StandardScaler(), numerical_features)\n",
    "#     ],\n",
    "#     remainder='passthrough'  # Keep binary and ordinal features as is\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define selected features for At-Risk classification\n",
    "ordinal_features = ['parentalsupport']\n",
    "numerical_features = ['studytimeweekly', 'absences', 'gpa']\n",
    "\n",
    "# Column transformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scale', StandardScaler(), numerical_features),  # Scale numerical features\n",
    "        ('ordinal', OrdinalEncoder(), ordinal_features) # Encode ordinal features\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Model Training and Evaluation.**\n",
    "\n",
    "To identify the best model, we can train multiple classifiers and evaluate their performance using accuracy, F1-score, and AUC-ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy  F1-Score   AUC-ROC\n",
      "1              XGBoost  0.993737  0.987124  0.999881\n",
      "0        Random Forest  0.987474  0.973913  0.999713\n",
      "2  Logistic Regression  0.964509  0.925764  0.993789\n",
      "3                  SVM  0.962422  0.924370  0.993407\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100,  max_depth=10, min_samples_split=10, min_samples_leaf=5),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', max_depth=5, learning_rate=0.1, n_estimators=100, subsample=0.8, colsample_bytree=0.8, verbosity=0),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'SVM': SVC(probability=True)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.fit(X_train, y_train)  \n",
    "    \n",
    "    # Predict\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]  # Probabilities for AUC-ROC\n",
    "    \n",
    "    # Evaluate performance\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    results.append({'Model': name, 'Accuracy': acc, 'F1-Score': f1, 'AUC-ROC': auc})\n",
    "\n",
    "# Convert results to DataFrame and display\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.sort_values(by=\"AUC-ROC\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models still perform exceptionally well on train our data. We can proceed to check for overfitting  by comparing Train and Test test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas==1.5.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting & Underfitting Checks\n",
    "\n",
    "Now that we have a working pipeline, we need to compare train vs test performance to check for overfitting or underfitting.\n",
    "\n",
    "**1. Train-Test Performance Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Train Accuracy  Test Accuracy  Train F1   Test F1  \\\n",
      "1              XGBoost        1.000000       0.993737  1.000000  0.987124   \n",
      "0        Random Forest        0.998955       0.987474  0.997817  0.973913   \n",
      "2  Logistic Regression        0.971772       0.964509  0.941304  0.925764   \n",
      "3                  SVM        0.978045       0.962422  0.954048  0.924370   \n",
      "\n",
      "   Train AUC  Test AUC  \n",
      "1   1.000000  0.999881  \n",
      "0   1.000000  0.999713  \n",
      "2   0.996579  0.993789  \n",
      "3   0.997280  0.993407  \n"
     ]
    }
   ],
   "source": [
    "# 1. Train-Test Performance Check\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Train Performance\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_train_proba = pipeline.predict_proba(X_train)[:, 1]\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "    train_auc = roc_auc_score(y_train, y_train_proba)\n",
    "    \n",
    "    # Test Performance\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    y_test_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "    test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "    \n",
    "    # Append all metrics correctly in one row\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Train Accuracy': train_acc, 'Test Accuracy': test_acc,\n",
    "        'Train F1': train_f1, 'Test F1': test_f1,\n",
    "        'Train AUC': train_auc, 'Test AUC': test_auc\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.sort_values(by=\"Test AUC\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Test F1</th>\n",
       "      <th>Train AUC</th>\n",
       "      <th>Test AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.998955</td>\n",
       "      <td>0.987474</td>\n",
       "      <td>0.997817</td>\n",
       "      <td>0.973913</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.971772</td>\n",
       "      <td>0.964509</td>\n",
       "      <td>0.941304</td>\n",
       "      <td>0.925764</td>\n",
       "      <td>0.996579</td>\n",
       "      <td>0.993789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.978045</td>\n",
       "      <td>0.962422</td>\n",
       "      <td>0.954048</td>\n",
       "      <td>0.924370</td>\n",
       "      <td>0.997280</td>\n",
       "      <td>0.993407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train Accuracy  Test Accuracy  Train F1   Test F1  \\\n",
       "0        Random Forest        0.998955       0.987474  0.997817  0.973913   \n",
       "1              XGBoost        1.000000       0.993737  1.000000  0.987124   \n",
       "2  Logistic Regression        0.971772       0.964509  0.941304  0.925764   \n",
       "3                  SVM        0.978045       0.962422  0.954048  0.924370   \n",
       "\n",
       "   Train AUC  Test AUC  \n",
       "0   1.000000  0.999713  \n",
       "1   1.000000  0.999881  \n",
       "2   0.996579  0.993789  \n",
       "3   0.997280  0.993407  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest & XGBoost are overfitting, we can try and improve generalization by modifying the parameters for both models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Cross-Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  CV Accuracy  CV F1-Score  CV AUC-ROC\n",
      "1              XGBoost     0.994774     0.989034    0.999858\n",
      "0        Random Forest     0.990588     0.980146    0.999513\n",
      "3                  SVM     0.977522     0.952994    0.996797\n",
      "2  Logistic Regression     0.971769     0.941165    0.996399\n"
     ]
    }
   ],
   "source": [
    "cv_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_accuracy = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
    "    cv_f1 = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='f1').mean()\n",
    "    cv_auc = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='roc_auc').mean()\n",
    "    \n",
    "    cv_results.append({'Model': name, 'CV Accuracy': cv_accuracy, 'CV F1-Score': cv_f1, 'CV AUC-ROC': cv_auc})\n",
    "\n",
    "# Convert to DataFrame\n",
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "print(cv_results_df.sort_values(by=\"CV AUC-ROC\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  CV Accuracy  CV F1-Score  CV AUC-ROC\n",
      "1              XGBoost     0.994774     0.989034    0.999858\n",
      "0        Random Forest     0.990588     0.980146    0.999513\n",
      "3                  SVM     0.977522     0.952994    0.996797\n",
      "2  Logistic Regression     0.971769     0.941165    0.996399\n"
     ]
    }
   ],
   "source": [
    "# Store CV results\n",
    "cv_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # Perform Cross-Validation\n",
    "    cv_accuracy = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    cv_f1 = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='f1')\n",
    "    cv_auc = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "    # Get predicted probabilities for AUC calculation\n",
    "    y_cv_pred = cross_val_predict(pipeline, X_train, y_train, cv=5, method='predict')\n",
    "    y_cv_proba = cross_val_predict(pipeline, X_train, y_train, cv=5, method='predict_proba')[:, 1]\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    avg_cv_accuracy = cv_accuracy.mean()\n",
    "    avg_cv_f1 = cv_f1.mean()\n",
    "    avg_cv_auc = cv_auc.mean()\n",
    "    \n",
    "    # Append results\n",
    "    cv_results.append({\n",
    "        'Model': name,\n",
    "        'CV Accuracy': avg_cv_accuracy,\n",
    "        'CV F1-Score': avg_cv_f1,\n",
    "        'CV AUC-ROC': avg_cv_auc\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "print(cv_results_df.sort_values(by=\"CV AUC-ROC\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation (CV) results are still quite high, indicating strong performance across different data splits. However, XGBoost and Random Forest are still showing near-perfect AUC-ROC scores (~0.999), which strongly suggests overfitting.\n",
    "\n",
    "SVM and Logistic Regression show more reasonable generalization from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Define the parameter grid\n",
    "# rf_param_grid = {\n",
    "#     'n_estimators': [100, 200, 300], \n",
    "#     'max_depth': [5, 10, 15, None],  \n",
    "#     'min_samples_split': [2, 5, 10],  \n",
    "#     'min_samples_leaf': [1, 2, 4],  \n",
    "#     'max_features': ['sqrt', 'log2']\n",
    "# }\n",
    "\n",
    "# # Initialize the model\n",
    "# rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# # Grid search with 5-fold CV\n",
    "# rf_grid_search = GridSearchCV(rf_model, rf_param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=2)\n",
    "# rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Best parameters & score\n",
    "# print(\"Best RF Parameters:\", rf_grid_search.best_params_)\n",
    "# print(\"Best RF AUC-ROC:\", rf_grid_search.best_score_)\n",
    "\n",
    "# -----------------------------7 MINUTES RUNTIME--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Random Forest Performance on Test Set:\n",
      "Accuracy: 0.9937\n",
      "F1-Score: 0.9871\n",
      "AUC-ROC: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest with best parameters\n",
    "best_rf = RandomForestClassifier(\n",
    "    max_depth=10, \n",
    "    max_features='sqrt', \n",
    "    min_samples_leaf=1, \n",
    "    min_samples_split=2, \n",
    "    n_estimators=300, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "y_pred_proba_rf = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate performance\n",
    "rf_test_acc = accuracy_score(y_test, y_pred_rf)\n",
    "rf_test_f1 = f1_score(y_test, y_pred_rf)\n",
    "rf_test_auc = roc_auc_score(y_test, y_pred_proba_rf)\n",
    "\n",
    "# Print test results\n",
    "print(\"Final Random Forest Performance on Test Set:\")\n",
    "print(f\"Accuracy: {rf_test_acc:.4f}\")\n",
    "print(f\"F1-Score: {rf_test_f1:.4f}\")\n",
    "print(f\"AUC-ROC: {rf_test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuning XGBoost Model with GridSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FRANK\\anaconda3\\envs\\learn-env\\lib\\site-packages\\xgboost\\data.py:173: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGB Parameters: {'subsample': 1.0, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.2, 'lambda': 0, 'colsample_bytree': 1.0}\n",
      "Best XGB AUC-ROC: 0.9998804721350666\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300], \n",
    "    'max_depth': [3, 5, 7, 10],  \n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],  \n",
    "    'subsample': [0.6, 0.8, 1.0],  \n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],  \n",
    "    'lambda': [0, 0.1, 1, 10]  # L2 Regularization\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Randomized search with 5-fold CV\n",
    "xgb_random_search = RandomizedSearchCV(xgb_model, xgb_param_grid, n_iter=20, cv=5, scoring='roc_auc', n_jobs=-1, verbose=2, random_state=42)\n",
    "xgb_random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters & score\n",
    "print(\"Best XGB Parameters:\", xgb_random_search.best_params_)\n",
    "print(\"Best XGB AUC-ROC:\", xgb_random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final XGBoost Performance on Test Set:\n",
      "Accuracy: 0.9937\n",
      "F1-Score: 0.9871\n",
      "AUC-ROC: 0.9998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FRANK\\anaconda3\\envs\\learn-env\\lib\\site-packages\\xgboost\\data.py:173: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "c:\\Users\\FRANK\\anaconda3\\envs\\learn-env\\lib\\site-packages\\xgboost\\data.py:173: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# Train XGBoost with best parameters\n",
    "best_xgb = XGBClassifier(\n",
    "    max_depth=3,\n",
    "    learning_rate=0.2,\n",
    "    n_estimators=100,\n",
    "    subsample=1.0,\n",
    "    colsample_bytree=1.0,\n",
    "    reg_lambda=0,  # 'lambda' in XGBoost API\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb = best_xgb.predict(X_test)\n",
    "y_pred_proba_xgb = best_xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate performance\n",
    "xgb_test_acc = accuracy_score(y_test, y_pred_xgb)\n",
    "xgb_test_f1 = f1_score(y_test, y_pred_xgb)\n",
    "xgb_test_auc = roc_auc_score(y_test, y_pred_proba_xgb)\n",
    "\n",
    "# Print test results\n",
    "print(\"Final XGBoost Performance on Test Set:\")\n",
    "print(f\"Accuracy: {xgb_test_acc:.4f}\")\n",
    "print(f\"F1-Score: {xgb_test_f1:.4f}\")\n",
    "print(f\"AUC-ROC: {xgb_test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Both models have identical Accuracy (0/9937) and F1-Score (0.9871).\n",
    "- Random Forest AUC-ROC = 1.0 on Test Set; suggesting possible overfitting because perfect AUC-ROC on test data is extremely rare.\n",
    "- XGBoost has slightly lower test AUC-ROC (0.9998) but generalizes slightly better with minimal train-test gap\n",
    "- Random Forest might be slighly prone to memorizing the data, making XGBoost a safer bet for real-world deployment, in addition to being faster overall and efficient for larger datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving & Model Deployment\n",
    "**Save Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained XGBoost model\n",
    "joblib.dump(best_xgb, \"xgboost_student_risk_model.pkl\")\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model Accuracy: 0.9937369519832986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FRANK\\anaconda3\\envs\\learn-env\\lib\\site-packages\\xgboost\\data.py:173: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "loaded_model = joblib.load(\"xgboost_student_risk_model.pkl\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# Check accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Loaded Model Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy matches earlier results, we're good to go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deployment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x80\\x04\\x95\\x0e\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x0fxgboost.sklearn\\x94\\x8c\\rXGBClassifier\\x94\\x93\\x94)\\x81\\x94}\\x94(\\x8c\\x0cn_estimators\\x94Kd\\x8c\\tobjective\\x94\\x8c\\x0fbinary:logistic\\x94'\n"
     ]
    }
   ],
   "source": [
    "with open(\"xgboost_student_risk_model.pkl\", \"rb\") as file:\n",
    "    content = file.read()\n",
    "print(content[:100])  # Print first 100 bytes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
