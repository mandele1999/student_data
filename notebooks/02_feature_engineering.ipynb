{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Feature Engineering Notebook. \n",
    "\n",
    "**Notebook Objective:** \n",
    "\n",
    "In this notebook, we engineer new features and transform existing ones to prepare the data for modeling. This includes one-hot encoding, scaling, and combining binary and ordinal features. The final output is a clean, `model-ready` dataset saved for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Load Raw Processed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully! Shape: (2392, 15)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "studentid",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gender",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ethnicity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "parentaleducation",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "studytimeweekly",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "absences",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tutoring",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "parentalsupport",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "extracurricular",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sports",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "music",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "volunteering",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gpa",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gradeclass",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7352037d-11c8-476d-89dc-521510e2ad5b",
       "rows": [
        [
         "0",
         "1001",
         "17",
         "1",
         "0",
         "2",
         "19.83372280785472",
         "7",
         "1",
         "2",
         "0",
         "0",
         "1",
         "0",
         "2.929195591667681",
         "2.0"
        ],
        [
         "1",
         "1002",
         "18",
         "0",
         "0",
         "1",
         "15.40875605584674",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "3.042914833436377",
         "1.0"
        ],
        [
         "2",
         "1003",
         "15",
         "0",
         "2",
         "3",
         "4.21056976881226",
         "26",
         "0",
         "2",
         "0",
         "0",
         "0",
         "0",
         "0.1126022544661815",
         "4.0"
        ],
        [
         "3",
         "1004",
         "17",
         "1",
         "0",
         "3",
         "10.028829473958217",
         "14",
         "0",
         "3",
         "1",
         "0",
         "0",
         "0",
         "2.0542181397029484",
         "3.0"
        ],
        [
         "4",
         "1005",
         "17",
         "1",
         "0",
         "2",
         "4.6724952729713305",
         "17",
         "1",
         "3",
         "0",
         "0",
         "0",
         "0",
         "1.2880611817953875",
         "4.0"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>studentid</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>parentaleducation</th>\n",
       "      <th>studytimeweekly</th>\n",
       "      <th>absences</th>\n",
       "      <th>tutoring</th>\n",
       "      <th>parentalsupport</th>\n",
       "      <th>extracurricular</th>\n",
       "      <th>sports</th>\n",
       "      <th>music</th>\n",
       "      <th>volunteering</th>\n",
       "      <th>gpa</th>\n",
       "      <th>gradeclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.833723</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.929196</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.408756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.042915</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.210570</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112602</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.028829</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.054218</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.672495</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.288061</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   studentid  age  gender  ethnicity  parentaleducation  studytimeweekly  \\\n",
       "0       1001   17       1          0                  2        19.833723   \n",
       "1       1002   18       0          0                  1        15.408756   \n",
       "2       1003   15       0          2                  3         4.210570   \n",
       "3       1004   17       1          0                  3        10.028829   \n",
       "4       1005   17       1          0                  2         4.672495   \n",
       "\n",
       "   absences  tutoring  parentalsupport  extracurricular  sports  music  \\\n",
       "0         7         1                2                0       0      1   \n",
       "1         0         0                1                0       0      0   \n",
       "2        26         0                2                0       0      0   \n",
       "3        14         0                3                1       0      0   \n",
       "4        17         1                3                0       0      0   \n",
       "\n",
       "   volunteering       gpa  gradeclass  \n",
       "0             0  2.929196         2.0  \n",
       "1             0  3.042915         1.0  \n",
       "2             0  0.112602         4.0  \n",
       "3             0  2.054218         3.0  \n",
       "4             0  1.288061         4.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load preprocessed dataset\n",
    "processed_data_path = \"../data/processed/processed_student_data.csv\"\n",
    "df = pd.read_csv(processed_data_path)\n",
    "\n",
    "print(f\"Data loaded successfully! Shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Categorical Variables\n",
    "\n",
    "- Binary Categorical Variables: \n",
    "  - `Gender, Tutoring, Extracurricular, Sports, Music, Volunteering`\n",
    "    - These are already binary (0 or 1). No further encoding needed.\n",
    "### Scaling\n",
    "\n",
    "- Ordinal Variables:\n",
    "  - `ParentalSupport`:\n",
    "    - Since this has an inherent order, we can keep it as is (0 to 4). Machine learning models will handle this naturally\n",
    "- Norminal Variables:\n",
    "  - `Ethnicity, ParentalEducation`:\n",
    "    - These have no inherent order, so we'll use One-Hot Encoding to avoid assigning artificial ordinal relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2: Define Column Types & Separate Features/Targets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and targets separated! X shape: (2392, 12), y shape: (2392, 2)\n"
     ]
    }
   ],
   "source": [
    "# 2. Define feature types\n",
    "binary_features = ['gender', 'tutoring', 'extracurricular', 'sports', 'music', 'volunteering']\n",
    "ordinal_features = ['parentalsupport', 'parentaleducation']\n",
    "nominal_features = ['ethnicity']\n",
    "numerical_features = ['studytimeweekly', 'absences', 'age']\n",
    "\n",
    "features = binary_features + ordinal_features + nominal_features + numerical_features\n",
    "target_cols = ['gpa', 'gradeclass']\n",
    "\n",
    "# 3. Split into X and y\n",
    "X = df[features]\n",
    "y = df[target_cols]\n",
    "print(f\"Features and targets separated! X shape: {X.shape}, y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3: Define Preprocessor (Base Transformer)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define base preprocessor\n",
    "base_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(drop='first'), nominal_features),\n",
    "        ('scale', StandardScaler(), numerical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keeps binary + ordinal as-is\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4: ColumnNameTransformer to Retain Column Names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Custom transformer to retain feature names\n",
    "class ColumnNameTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, transformer, feature_names):\n",
    "        self.transformer = transformer\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.transformer.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_t = self.transformer.transform(X)\n",
    "        return pd.DataFrame(X_t, columns=self.feature_names, index=X.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5: Fit Preprocessor and Get Column Names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor fitted and column names extracted!\n"
     ]
    }
   ],
   "source": [
    "# 6. Fit preprocessor to data\n",
    "base_preprocessor.fit(X)\n",
    "\n",
    "# 7. Get transformed column names\n",
    "encoded_columns = base_preprocessor.named_transformers_['onehot'].get_feature_names_out(nominal_features)\n",
    "scaled_columns = numerical_features\n",
    "remaining_columns = binary_features + ordinal_features\n",
    "\n",
    "# Final column order\n",
    "all_transformed_columns = list(encoded_columns) + scaled_columns + remaining_columns\n",
    "print(f\"Preprocessor fitted and column names extracted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6: Wrap Preprocessor and Save**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor pipeline saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# 8. Wrap with ColumnNameTransformer\n",
    "wrapped_preprocessor = ColumnNameTransformer(base_preprocessor, feature_names=all_transformed_columns)\n",
    "\n",
    "# 9. Create and save pipeline\n",
    "preprocessor_pipeline = Pipeline([(\"preprocessor\", wrapped_preprocessor)])\n",
    "joblib.dump(preprocessor_pipeline, \"../models/preprocessor_pipeline.pkl\")\n",
    "print(f\"Preprocessor pipeline saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7: Transform Features & Create Final Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risk_flag column added!\n",
      "Class distribution (risk_flag):\n",
      "1    1274\n",
      "0    1118\n",
      "Name: risk_flag, dtype: int64\n",
      "Feature-engineered dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# 10. Apply transformation\n",
    "X_transformed_df = preprocessor_pipeline.transform(X)\n",
    "\n",
    "# 11. Combine with targets\n",
    "final_df = pd.concat([X_transformed_df, y.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# 12. Create risk_flag based on GPA\n",
    "final_df['risk_flag'] = final_df['gpa'].apply(lambda gpa: 1 if gpa < 2.0 else 0)\n",
    "print(\"risk_flag column added!\")\n",
    "\n",
    "# 13. View distribution\n",
    "print(\"Class distribution (risk_flag):\")\n",
    "print(final_df['risk_flag'].value_counts())\n",
    "\n",
    "# 14. Save feature-engineered dataset\n",
    "final_df.to_csv(\"../data/feature_engineered_student_data.csv\", index=False)\n",
    "print(\"Feature-engineered dataset saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
